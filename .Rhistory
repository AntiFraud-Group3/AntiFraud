Criteria <- data.frame(cvals)
names(Criteria) <- c('Rsq', 'Adj.Rsq', 'Cp', 'AIC', 'BIC', 'PRESS')
rownames(Criteria) <- c('1', 'x1', 'x6', 'x1 + x6')
round(Criteria, 4)
tinytex::reinstall_tinytex()
install.packages('corrplot')
library(corrplot)
install.packages('caret')
cancel
View(A_mat)
mobile_money_data <- read.csv(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/PS_20174392719_1491204439457_log.csv")
library(dplyr)
library(ggplot2)
library(tidyr)
str(mobile_money_data)
summary(mobile_money_data)
fraud_count <- mobile_money_data %>% group_by(type) %>% select(isFraud, isFlaggedFraud) %>% summarise(Fraud_Frequency = sum(isFraud), Flagged_Frequency = sum(isFlaggedFraud)) %>% pivot_longer(cols = ends_with("Frequency"), names_to = "Frequency")
fraud_count
ggplot(data = fraud_count, aes(x = type, y = value, fill = Frequency)) + geom_col(position = position_dodge(0.7), width = 0.6) + labs(y = "Number of fraudulent cases")  + geom_text(aes(label = value), position = position_dodge(0.7), size = 3) + theme_minimal()
transaction_with_step <- mobile_money_data %>% group_by(step) %>% summarise(Transaction_Frequency = n())
transaction_with_step
ggplot(data = transaction_with_step, aes(x = step, y = Transaction_Frequency)) + geom_line() + labs(x = "Time Period",y = "Number of Transactions") + geom_smooth() + theme_minimal()
fraud_with_step <- mobile_money_data %>% group_by(step) %>% select(isFraud) %>% summarise(Fraud_Frequency = sum(isFraud))
fraud_with_step
ggplot(data = fraud_with_step, aes(x = step, y = Fraud_Frequency)) + geom_line() + labs(x = "Time Period",y = "Number of fraudulent cases") + geom_smooth() + theme_minimal()
library(data.table)
View(fraud_count)
View(fraud_count)
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
library(ROSE)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalanced data
corr_mat <- as.data.frame(cor(credit_card_data)) %>% select('Class') %>% arrange(Class)
corr_mat
rel_high_corr_Class <- credit_card_data %>% select(-contains(c('V13','V15','V23','V22', 'V25', 'V26', 'Amount'))) # Drop variables with low correlation to Class
rel_high_corr_Class
set.seed(1005)
rose_train <- ROSE(Class ~., data = rel_high_corr_Class)$data
table(rose_train$Class) # Relatively Balanced dataset
scaled_data <- scale(rose_train %>% select(-contains('Class'))) # To standardize data
wss <- (nrow(scaled_data)-1)*sum(apply(scaled_data, 2, var))
for (i in 2:20) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
kmeans_cluster_2 <- kmeans(scaled_data, centers = 2, nstart = 25)
str(kmeans_cluster_2)
p1 <- fviz_cluster(kmeans_cluster_2, data = scaled_data, ellipse.type = "convex") + theme_minimal() + ggtitle("k = 2")
# Append cluster No.
kmeans_data <- scaled_data %>% as.data.frame() %>% mutate(cluster = kmeans_cluster_2$cluster)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = credit_card_data$fraud)
table(x$cluster, x$fraud)
str(kmeans_cluster_2)
plot(p1)
scaled_data <- scale(rel_high_corr_Class %>% select(-contains('Class'))) # To standardize data
wss <- (nrow(scaled_data)-1)*sum(apply(scaled_data, 2, var))
for (i in 2:20) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
for (i in 2:20) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
kmeans_cluster_2 <- kmeans(scaled_data, centers = 2, nstart = 25)
str(kmeans_cluster_2)
# Append cluster No.
kmeans_data <- scaled_data %>% as.data.frame() %>% mutate(cluster = kmeans_cluster_2$cluster)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rel_high_corr_Class$fraud)
table(x$cluster, x$fraud)
length(x$cluster)
length(x$fraud)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rel_high_corr_Class$Class)
table(x$cluster, x$fraud)
p1 <- fviz_cluster(kmeans_cluster_2, data = scaled_data, ellipse.type = "convex") + theme_minimal() + ggtitle("k = 2")
plot(p1)
library(fpc)
install.packages(fpc)
install.packages("fpc")
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = credit_card_data$Class)
table(x$cluster, x$fraud) # 2 cluster results
clusplot(credit_card_data, kmeans_cluster_2$cluster, color=TRUE, shade=TRUE,
labels=2, lines=0)
library(fpc)
install.packages('mclust')
library(fpc)
library(mclust)
library(fpc)
clear
set.seed(1005)
fviz_cluster(kmeans_cluster_2), data = scaled_data, geom - c("point"), ellipse.type = "euclid")
fviz_cluster(kmeans_cluster_2, data = scaled_data, geom - c("point"), ellipse.type = "euclid")
fviz_cluster(kmeans_cluster_2, data = scaled_data, geom = c("point"), ellipse.type = "euclid")
fviz_cluster(kmeans_cluster_2, data = scaled_data, geom = c("point"), ellipse.type = "euclid")
fviz_nbclust(scaled_data, kmeans, method = "wss")
fviz_cluster(kmeans_cluster_2, data = scaled_data, geom = c("point"), ellipse.type = "euclid")
kmeans_cluster_2
kmeans_cluster_2
View(kmeans_cluster_2)
View(credit_card_data)
str(credit_card_data)
Class_count
class_count
for (i in 2:50) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
for (i in 2:30) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:30, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
scaled_data <- scale(credit_card_data %>% select(-contains('Class'))) # To standardize data
for (i in 2:30) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:30, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
for (i in 2:50) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
for (i in 2:50) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:50, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
fviz_nbclust(scaled_data, FUNcluster, method = c("silhouette", "wss", "gap_stat"))
fviz_nbclust(scaled_data, kmeans, method = c("silhouette", "wss", "gap_stat"))
kmeans_cluster_2$cluster
kmeans_cluster_2$size
kmeans_cluster_2$centers
kmeans_cluster_2$totss
kmeans_cluster_2$tot.withinss
kmeans_cluster_2$betweenss
fviz_nbclust(scaled_data, kmeans, method = c("silhouette", "wss", "gap_stat"))
gc()
fviz_nbclust(scaled_data, kmeans, method = silhouette))
fviz_nbclust(scaled_data, kmeans, method = silhouette)
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
fviz_nbclust(scaled_data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50")
kmeans_cluster_2$betweenss
clear
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
set.seed(1005)
scaled_data <- scale(credit_card_data %>% select(-contains('Class'))) # To standardize data
library(dplyr)
scaled_data <- scale(credit_card_data %>% select(-contains('Class'))) # To standardize data
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
library(cluster)
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
library(factoextra)
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
library(usethis)
usethis::edit_r_environ("project")
usethis::edit_r_environ(")
""
exit
"")
usethis::edit_r_environ()
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
set.seed(1005)
scaled_data <- scale(credit_card_data %>% select(-contains('Class'))) # To standardize data
scaled_data <- scale(credit_card_data %>% select(-contains('Class'))) # To standardize data
wss <- (nrow(scaled_data)-1)*sum(apply(scaled_data, 2, var))
for (i in 2:50) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
fviz_nbclust(scaled_data, kmeans, method = "silhouette")
for (i in 2:30) wss[i] <- sum(kmeans(scaled_data, center=i)$withiness)
plot(1:30, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
plot(1:42, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
library(DMwR)
library(caTools)
set.seed(1005)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_data[,-30] <- scale(credit_card_data[,-30]) # To standardize data
credit_card_data[,-30] <- scale(credit_card_data[,-30]) # To standardize data
credit_card_data[,-29] <- scale(credit_card_data[,-29]) # To standardize data
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data[!Class] <- scale(credit_card_data[!Class]) # To standardize data
credit_card_data[!'Class'] <- scale(credit_card_data[!'Class']) # To standardize data
credit_card_data[-'Class'] <- scale(credit_card_data[-'Class']) # To standardize data
credit_card_data[-c('Class')] <- scale(credit_card_data[-c('Class')]) # To standardize data
credit_card_data[, -30] <- scale(credit_card_data[,-30]) # To standardize data
scaled_data <- scale(credit_card_data %>% select(-contains('Class')))
split <- sample.split(scaled_data$Class, SplitRatio = 0.7)
credit_card_data[1:29] <- scale(credit_card_data %>% select(-contains('Class')))
scaled_data[,-30] <- scale(credit_card_data %>% select(-contains('Class')))
scaled_data[,30] <- credit_card_data[,30]
credit_card_data[,0]
scaled_data[,30] <- credit_card_data$Class
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(scaled_data$Class, SplitRatio = 0.7)
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(scaled_data, split == TRUE)
test <- subset(scaled_data, split == FALSE)
table(train$Class) # original counts in train dataset
smote_train <- SMOTE(Class ~., data = train)
table(train$Class) # original counts in train dataset
table(train$Class) # original counts in train dataset
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(scaled_data, split == TRUE)
head(train)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
smote_train <- SMOTE(Class ~., data = train)
smote_train <- SMOTE(Class ~., data = as.factor(train))
library(ROSE)
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
wss <- (nrow(rose_train)-1)*sum(apply(scaled_data, 2, var))
for (i in 2:30) wss[i] <- sum(kmeans(rose_train, center=i)$withiness)
plot(1:30, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
str(kmeans_cluster_2)
kmeans_cluster_2 <- kmeans(scaled_data, centers = 2, nstart = 25)
kmeans_cluster_2 <- kmeans(scaled_data, centers = 2, nstart = 25)
kmeans_cluster_2 <- kmeans(scaled_data, centers = 2, nstart = 25
)
kmeans_cluster_2 <- kmeans(rose_train, centers = 2, nstart = 25)
str(kmeans_cluster_2)
fviz_cluster(kmeans_cluster_2, data = rose_train, geom = c("point"), ellipse.type = "euclid")
# Append cluster No.
kmeans_data <- rose_train %>% as.data.frame() %>% mutate(cluster = kmeans_cluster_2$cluster)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = credit_card_data$Class)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rpse_train$Class)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rose_train$Class)
table(x$cluster, x$fraud) # 2 cluster results
clusplot(credit_card_data, kmeans_cluster_2$cluster, color=TRUE, shade=TRUE,labels=2, lines=0)
clusplot(rose_train, kmeans_cluster_2$cluster, color=TRUE, shade=TRUE,labels=2, lines=0)
kmeans_cluster_2$size
kmeans_cluster_2$centers
kmeans_cluster_2$totss
kmeans_cluster_2$tot.withinss
kmeans_cluster_2$betweenss
kmeans_cluster_2
kmeans_cluster_2$iter
kmeans_cluster_2$iter$isfault
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
library(ROSE)
library(caTools)
set.seed(1005)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
wss <- (nrow(rose_train)-1)*sum(apply(rose_train, 2, var))
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_date <- credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
rose_train <- as.matrix(rose_train)
rose_train <- as.matrix(rose_train)
wss <- (nrow(rose_train)-1)*sum(apply(rose_train, 2, var))
for (i in 2:30) wss[i] <- sum(kmeans(rose_train, center=i)$withiness)
rose_train <- as.matrix(rose_train %>% select (-contains("Class"))
)
rose_train <- as.matrix(rose_train %>% select (-contains(c("Class"))))
rose_train <- as.matrix(rose_train %>% select(-contains(c("Class"))))
rose_train <- as.matrix(rose_train[-c(30)])
wss <- (nrow(rose_train)-1)*sum(apply(rose_train, 2, var))
for (i in 2:30) wss[i] <- sum(kmeans(rose_train, center=i)$withiness)
head(rose_train)
rose_train <- ROSE(Class ~., data = train)$data
new_rose_train <- as.matrix(rose_train[-c(30)])
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_date <- credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
str(credit_card_data)
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
library(ROSE)
library(caTools)
set.seed(1005)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
credit_card_date <- credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(credit_card_data$Class, SplitRatio = 0.7)
train <-  subset(credit_card_data, split == TRUE)
test <- subset(credit_card_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
new_rose_train <- as.matrix(rose_train[-c(30)])
wss <- (nrow(rose_train)-1)*sum(apply(rose_train, 2, var))
rose_train <- ROSE(Class ~., data = train)$data
rose_train <- as.matrix(rose_train[-c(30)])
wss <- (nrow(rose_train)-1)*sum(apply(rose_train, 2, var))
for (i in 2:30) wss[i] <- sum(kmeans(rose_train, center=i)$withiness)
plot(1:30, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
kmeans_cluster_2 <- kmeans(rose_train, centers = 2, nstart = 25)
str(kmeans_cluster_2)
fviz_cluster(kmeans_cluster_2, data = rose_train, geom = c("point"), ellipse.type = "euclid")
# Append cluster No.
kmeans_data <- rose_train %>% as.data.frame() %>% mutate(cluster = kmeans_cluster_2$cluster)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rose_train$Class)
library(data.table)
credit_card_data <- fread(file="/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/creditcard.csv")
library(tidyverse)
library(dplyr)
library(cluster)
library(factoextra)
library(caret)
library(ROSE)
library(caTools)
set.seed(1005)
str(credit_card_data)
summary(credit_card_data)
sapply(credit_card_data, function(x)(sum(is.na(x)))) # No missing value
class_count <- credit_card_data %>% mutate(class_count = factor(Class)) %>% group_by(Class) %>% summarize(Frequency = n()) %>% mutate(Percent = round(Frequency/sum(Frequency)*100, 1))
class_count # 2% of fraud cases -> imbalance dataset
credit_card_data <- credit_card_data[,-1] # remove time
credit_card_data$Class <- as.factor(credit_card_data$Class)
levels(credit_card_data$Class) <- c("Not_Fraud", "Fraud")
scaled_data <- credit_card_data %>% mutate(across(where(is.numeric), scale))
split <- sample.split(scaled_data$Class, SplitRatio = 0.7)
train <-  subset(scaled_data, split == TRUE)
test <- subset(scaled_data, split == FALSE)
table(train$Class) # original counts in train dataset
rose_train <- ROSE(Class ~., data = train)$data
table(rose_train$Class)
rose_train_matrix <- as.matrix(rose_train[-c(30)])
wss <- (nrow(rose_train_matrix)-1)*sum(apply(rose_train_matrix, 2, var))
for (i in 2:20) wss[i] <- sum(kmeans(rose_train_matrix, center=i)$withiness)
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares") # From elbow method, 2 is the optimal number of clusters for this dataset
kmeans_cluster_2 <- kmeans(rose_train_matrix, centers = 2, nstart = 25)
str(kmeans_cluster_2)
fviz_cluster(kmeans_cluster_2, data = rose_train_matrix, geom = c("point"), ellipse.type = "euclid")
# Append cluster No.
kmeans_data <- rose_train_matrix %>% as.data.frame() %>% mutate(cluster = kmeans_cluster_2$cluster)
# Check the clusters against the fraud lable
x <- kmeans_data %>% mutate(fraud = rose_train$Class)
table(x$cluster, x$fraud) # 2 cluster results
kmeans_cluster_2$size
kmeans_cluster_2$centers
kmeans_cluster_2$totss
kmeans_cluster_2$tot.withinss
kmeans_cluster_2$betweenss
kmeans_cluster_2
# train
train_inpatient <- read.csv("W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/group_proj.Rmd")
# train
train_inpatient <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Inpatientdata-1542969243754.csv")
train_outpatient <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Outpatientdata-1542969243754.csv")
train_beneficiary <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Beneficiarydata-1542969243754.csv")
# test
test <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test-1542969243754.csv")
test_inpatient <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Inpatientdata-1542969243754.csv")
test_outpatient <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Beneficiarydata-1542969243754.csv")
test_beneficiary <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Test_Beneficiarydata-1542969243754.csv")
# train
train <- test <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Train-1542969243754.csv")
# train
train <- test <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Train-1542869243754.csv")
# train
train <- test <- read.csv("/Users/W/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/group_proj/Medicare_fraud_data/Train-1542865627584.csv")
gc()
setwd("~/Downloads/HKU/M1/FITE7410 Financial Fraud Detection/GitHub/AntiFraud")
library('pacman')
p_load('tidyverse')
require('lubridate')
provider_data <- read_csv('data/Train.csv')
provider_data <- provider_data %>%
mutate(PotentialFraud = factor(ifelse(PotentialFraud == "Yes", 1, 0)))
table(provider_data$PotentialFraud) # 4904 non-fraud & 506 fraud
beneficiary_data <- read_csv('data/Train_Beneficiarydata.csv',
col_types = cols(.default = 'n',
BeneID = 'c',
DOB = 'D',
DOD = 'D',
# Factorized Gender
Gender = 'f',
Race = 'f',
State = 'f',
# kept the type as chr for now
RenalDiseaseIndicator = 'c',
County = 'f'))
View(beneficiary_data)
beneficiary_data <- beneficiary_data %>%
mutate_at(vars(matches("ChronicCond")), ~ifelse(. == "1", 0, 1)) %>%
mutate_at(vars(matches("ChronicCond")), as.factor) %>%
# changed 'Y' to 1 and factorize
mutate_at("RenalDiseaseIndicator", ~ifelse(. == 'Y', 1, 0)) %>%
mutate_at("RenalDiseaseIndicator", as.factor) %>%
# Removed NoOfMonths_PartACov & NoOfMonths_PartBCov
select(-c("NoOfMonths_PartACov", "NoOfMonths_PartBCov")) %>%
# dropped neg IP & OP annual reimbursement amount
subset(IPAnnualReimbursementAmt >= 0 & OPAnnualReimbursementAmt >= 0)
beneficiary_data$alive = factor(ifelse(is.na(beneficiary_data$DOD), 1, 0))
beneficiary_data$age = trunc((beneficiary_data$DOB  %--% Sys.Date()) / years(1))
inpatient_data <- read_csv('data/Train_Inpatientdata.csv',
# Updated col_types to keep the possible letter in codes
col_types = cols(.default = 'c',
ClaimStartDt = 'D',
ClaimEndDt = 'D',
InscClaimAmtReimbursed = 'n',
AdmissionDt = 'D',
DeductibleAmtPaid = 'n',
DischargeDt = 'D'
))
inpatient_data <- inpatient_data %>%
mutate_at(vars(matches("Code")), ~replace_na(., -1))  %>%
mutate_at(vars(matches("Code")), as.factor) %>%
mutate_at(vars(matches("Physician")), ~replace_na(., "Non-Exist")) %>%
# Should we assume NA in deductibleAmtPaid to be 0 ???
mutate_at("DeductibleAmtPaid", ~replace_na(., 0))
View(inpatient_data)
inpatient_data$DaysAdmittedInHospital = as.numeric(difftime(inpatient_data$DischargeDt,
inpatient_data$AdmissionDt,
units = "days"))
inpatient_data$TotalAmt = inpatient_data$InscClaimAmtReimbursed + inpatient_data$DeductibleAmtPaid
inpatient_data$AvgPerDay = round(inpatient_data$TotalAmt/inpatient_data$DaysAdmittedInHospital,2)
outpatient_data <- read_csv('data/Train_Outpatientdata.csv',
# Updated col_types to keep the possible letter in codes
col_types = cols(.default = 'c',
ClaimStartDt = 'D',
ClaimEndDt = 'D',
InscClaimAmtReimbursed = 'n',
DeductibleAmtPaid = 'n'
))
outpatient_data <- outpatient_data %>%
mutate_at(vars(matches("Code")), ~replace_na(., -1))  %>%
mutate_at(vars(matches("Code")), as.factor) %>%
mutate_at(vars(matches("Physician")), ~replace_na(., "Non-Exist"))
outpatient_data$TotalAmt = outpatient_data$InscClaimAmtReimbursed + outpatient_data$DeductibleAmtPaid
View(outpatient_data)
